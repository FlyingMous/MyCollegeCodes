{"name":"Mycollegecodes","tagline":"Programs I made while I'm in college","body":"Hu3 Team GPU610 - Seneca College\r\n\r\n== Progress ==\r\n=== Assignment 1 ===\r\n====Bruno's Findings====\r\nI started off with this simple heat equation\r\n\r\nIt's interesting because the calculation involves taking the average between each matrix element's neighbour(north, south, east and west) and keeps on doing it over and over again until you get a precise calculation(when the biggest difference between the new calculated element and the older is smaller than the defined Epsilon error margin).\r\nLike this you are able to get a nice heat dispersion calculation.\r\n\r\nI was worried about data dependency, since, as I said, each element depends on each other to be calculated. But this solution uses 2 matrix, one old and one new, where the new matrix will receive the average value of the old matrix and, if the difference is still bigger than epsilon, then the old matrix receives the values of the new matrix and the whole iteration happens again, where the new matrix  is going to receive the average values of the old matrix, that now holds the most recent values.\r\n\r\nSo this is a good candidate for parallelization because we can send each iteration of the average calculation to a different GPU thread and since this is a simple average calculation, the GPU will be able to do it.\r\nRunning with a 1000x1000 matrix, with a epsilon error factor of  0.001, the program took almost 5 minutes to run completely and 99% of the time was on the getHeat() method (the heat calculation core).\r\n\r\n\r\n![](http://zenit.senecac.on.ca/wiki/imgs/Execution-NO_CUDA.JPG)\r\n\r\n====Carlos's Findings====\r\n\r\nThe array processing is a good choice and it is used in many applications, for example game development and image processing. It can calculate the transformation of a game world scene and its objects; besides, add filters on images as we can see in mobile apps such as Instagram.\r\n\r\nIt is a good candidate because it operates simple and repetitive calculations that can be divide among CUDA processors.\r\n\r\n====Conclusion====\r\n\r\nAfter analyzing both solutions and their applications, we have chosen the Heat Equation because of the number of different algorithms that we can find to solve array processing problems, such as CBLAS and cuBLAS. Due to the possibility of doing something that is not often done, we will work with the Heat Equation during this semester.\r\n\r\n=== Assignment 2 ===\r\n====CUDA Coding====\r\nBased on assignment 1, we added the source code to make possible the program to be executed on a CUDA device, as follows.\r\n\r\n<pre>\r\n\r\n__global__ void copyMat(const double *w, double *u){\r\n\r\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\r\n\r\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\r\n\r\n\tif (i < M && j < N) {\r\n\r\n\t\tu[i * M + j] = w[i * M + j];\r\n\r\n\t}\r\n\r\n\t__syncthreads();\r\n\r\n}\r\n\r\n__global__ void calcHeat(double *w, const double *u, double *d, int m, int n, double* d_array){\r\n\r\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\r\n\r\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\r\n\r\n\tif ( i == 0 )i++; \r\n\r\n\tif ( j == 0 )j++;\r\n\r\n\tif (i < m && j < n) {\r\n\r\n\t\tw[i * m + j] = (u[(i - 1) * m + j] + u[(i + 1) * m + j] + u[i * m + (j - 1)] + u[i * m + (j + 1)]) / 4.0;\r\n\r\n\t\td_array[i * m + j] = w[i * m + j] - u[i * m + j];\r\n\r\n\t\tif( d_array[i * m + j] < 0 ){d_array[i * m + j] *= -1;}\r\n\r\n\t}\r\n\r\n\t*d = -1;\r\n\r\n\t__syncthreads();\r\n\r\n}\r\n\r\n__global__ void bigDiff(double* d_array, double* d, int m, int n){\r\n\r\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\r\n\r\n\r\n\r\n\tfor (int x = 1; i+x < m*n; x*=2) {\r\n\r\n\t\tif (d_array[i] > *d || d_array[i + x] > *d){\r\n\r\n\t\t\tif (d_array[i] > d_array[i + x])\r\n\r\n\t\t\t\t*d = d_array[i];\r\n\r\n\t\t\telse\r\n\r\n\t\t\t\t*d = d_array[i + x];\r\n\r\n\t\t}\r\n\r\n\t\t__syncthreads();\r\n\r\n\t}\r\n\r\n}\r\n\r\n</pre>\r\n\r\nMoreover, we made the input of the error tolerance (Epsilon) to be set on the code. After lots of difficulties found while we were coding, we finally got good results in comparison with the code of assignment 1. The runtime was decreased, and it made us to see the power that CUDA may provide to optimize the processing.\r\n\r\n=== Assignment 3 ===\r\n\r\n====CUDA Coding====\r\nBased on assignment 2, we made optimizations to speed up the execution, as follows.\r\n\r\n<pre>\r\n__global__ void copyMat(const float *w, float *u){\r\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\r\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\r\n\tif (i < M && j < N) {\r\n\t\tu[i * M + j] = w[i * M + j];\r\n\t}\r\n\t__syncthreads();\r\n}\r\n__global__ void calcHeat(float *w, float *u, float *d, int m, int n, float* d_array){\r\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\r\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\r\n\tint tx = threadIdx.x;\r\n\tint ty = threadIdx.y;\r\n\r\n\t__shared__ float s_u[ntpb][ntpb];\r\n\t__shared__ float s_w[ntpb][ntpb];\r\n\t__shared__ float s_dif[ntpb][ntpb];\r\n\tif (tx < ntpb && ty < ntpb) {\r\n\t\ts_w[ty][tx] = w[j * M + i];\r\n\t\ts_u[ty][tx] = w[j * M + i];\r\n\t}\r\n\t__syncthreads();\r\n\r\n\tif ( ( tx < (ntpb-1) && ty < (ntpb-1) ) && ( tx >0 && ty > 0 ) && ( i < M && j < N ) ) {\r\n\t\ts_w[ty][tx] = ( s_u[ty - 1][tx] + s_u[ty + 1][tx] + s_u[ty][tx - 1] + s_u[ty][tx + 1] ) / 4.0;\r\n\r\n\t\ts_dif[ty][tx] = fabsf(s_w[ty][tx] - s_u[ty][tx]);\r\n\r\n\t\t//if (s_dif[ty][tx] < 0){ s_dif[ty][tx] *= -1; }\r\n\t}\r\n\t__syncthreads();\r\n\tif (tx < ntpb && ty < ntpb) {\r\n\t\tw[j * M + i] = s_w[ty][tx];\r\n\t\t//u[j * M + i] = s_w[ty][tx];\r\n\t\td_array[j * M + i] = s_dif[ty][tx];\r\n\t}\r\n\t__syncthreads();\r\n}\r\n__global__ void bigDiff(float* d_array, float* d, int m, int n){\r\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\r\n\r\n\tfor (int x = 1; i + x < m*n; x *= 2) {\r\n\t\tif (d_array[i] > *d || d_array[i + x] > *d){\r\n\t\t\tif (d_array[i] > d_array[i + x])\r\n\t\t\t\t*d = d_array[i];\r\n\t\t\telse\r\n\t\t\t\t*d = d_array[i + x];\r\n\t\t}\r\n\t\t__syncthreads();\r\n\t}\r\n}\r\n</pre>\r\nWe made use of shared memory to speed up the memory access for the kernel, along with coalesced memory access. We were already doing a simple reduction for getting the biggest difference, but with these tow optimizations alone we were able to get a speed up of almost 50% from the first not-optimized CUDA solution.\r\nBecause the code works getting neighboring elements from the matrix, we had to make a bigger check on the heat calculation part, to avoid illegal memory access.\r\n\r\n====Comparing the results====\r\nAs a result of the source code included, it was possible to reduce the processing time. \r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}